## Monte Carlo Simulation 

### Learning Module 5
#### Background:

Monte Carlo Simulation is a method to estimate the probability of the outcomes of an uncertain event. It is based on a law of probability theory that says if we repeat an experiment many times, the average of the results will get closer to the true probability of those outcomes. 

First check out this video:
```{r, echo=FALSE}
knitr::include_url("https://www.youtube.com/embed/7TqhmX92P6U")
```

#### Reading
Then read this: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2924739/ for a understanding of the fundamentals.

#### How does this apply to hydrological modeling?

When modeling watershed hydrological processes, we often attempting to quantify<br><br>

  * watershed inputs <br>
      + e.g., precipitation <br>
  - watershed outputs <br>
      - e.g., [evapotranspiration](https://www.usgs.gov/special-topics/water-science-school/science/evapotranspiration-and-water-cycle#:~:text=Evapotranspiration%20includes%20water%20evaporation%20into,to%20the%20atmosphere%20via%20plants), [sublimation](https://www.usgs.gov/media/images/sublimation-occurs-snow-covered-mountains), runoff/discharge <br>
  - watershed storage <br>
      - precipitation that is not immediately converted to runoff or ET rather stored as snow or subsurface water. <br>

Imagine we are trying to predict the percentage of precipitation stored in a watershed after a storm event. We have learned that there are may factors that affect this prediction, like antecedent conditions, that may be difficult to measure directly. Monte Carlo Simulation can offer a valuable approach to estimate the probability of obtaining certain measurements when those factors can not be directly observed or measured. We can approximate the likelihood of specific measurement by simulating a range of possible scenarios. <br>

Monte Carlo Simulation is not only useful for estimating probabilities, but for conducting sensitivity analysis. In any model, there are usually several input parameters. Sensitivity analysis helps us understand how changes in these parameters affect the predicted values. To perform a sensitivity analysis using a Monte Carlo Simulation we can:

  - Define the realistic ranges for each parameter we want to analyze
  - Using Monte Carlo Simulation, randomly sample values from the defined ranges for each parameter
  - Analyze output to understand how different input sample values affect the predicted output

#### Example

Let's consider all of this in an example model called [WECOH - Watershed ECOHydrology](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2014WR016719). In this study, researchers (Nippgen et al.) were interested in the change in subsurface water storage through time and space on a daily and seasonal basis.

![Evolution of watershed connectivity](./images/wrcr21497-fig-0009-m.jpg){width=50%}

<br/><br/>
The authors directly measured runoff/discharge, collected precipitation data at several points within the watershed, used remote sensing to estimate how much water was lost to evapotranspiration, and used digital elevation models to characterize the watershed topography. As we learned in the hydrograph separation module, topographic characteristics can have a significant impact on storage. <br>
Though resources like [USDA's Web Soil Survey](https://websoilsurvey.sc.egov.usda.gov/app/) can provide a basic understanding underlying geology across a large region, characterizing the heterogeneous nature of soils within a watershed can be logistically unfeasible. To estimate the soil characteristics like storage capacity (how much water the soil can hold) and hydraulic conductivity (how easily water can move through soil) in the study watershed, the authors used available resources to determine the possible range of values for each of their unknown parameters. They then tested thousands of model simulations using randomly selected values with the predetermined range for each of the soil characteristics. They compared the simulated discharge from these simulations to the actual discharge measurements. The simulations that predicted discharge patterns that closely matched reality helped them to estimate the unknown soil properties. Additionally, from the results of these simulations, they could identify which model inputs had the most significant impact on the discharge predictions, and how sensitive the output was to changes in each parameter. In this case, they determined that the model and system were most sensitive to precipitation. This type of sensitivity analysis can help us interpret the relative importance of different parameters and understand the overall sensitivity of the model or system. The study is linked for your reference but a thorough reading is not required. 

#### Optional Reading
[This methods paper](https://www.researchgate.net/publication/262765548_Development_of_probability_distributions_for_urban_hydrologic_model_parameters_and_a_Monte_Carlo_analysis_of_model_sensitivity) by Knighton et al. is an example of how Monte Carlo Simulation was used to estimate hydraulic conductivity in an urban system with varied land-cover..

#### Generate a simulation with code 

For a 12-minute example in RStudio, check this out. If you are still learning the basics of R functionality, it may be helpful to code along with this video, pausing as needed. Note that this instruction is coding in an Rscript (after opening RStudio > File > New File > R Script), rather than an Rmarkdown that we use in this class. 

```{r, echo=FALSE}
knitr::include_url("https://www.youtube.com/embed/inJsu-ygBfM")
```

### Repo link
[Download the repo for this lab HERE](https://github.com/tpcovino/05_monte_carlo.git){target="_blank"}

### Labwork (20 pnts)

In this lab/homework, you will use the transfer function model from the previous module for some sensitivity analysis using Monte Carlo simulations. The code is mostly the same as last module with some small adjustments to save the parameters from each Monte Carlo run. 
In this Monte Carlo simulation, we're testing how different parameter values affect simulated streamflow (discharge). Since we donâ€™t know the true values of certain model parameters (like b1, b2, b3, a, and b that you may recall from the transfer function), we randomly sample them within a reasonable range and run the model many times to see which parameter combinations best match observed streamflow data. Each iteration of the loop represents one possible "guess" at the true parameter values, and we evaluate how good that guess is using metrics like Nash-Sutcliffe Efficiency (NSE), Kling-Gupta Efficiency (KGE), Root Mean Square Error (RMSE), and Mean Absolute Error (MAE).
 After the completion of the MC runs, we will use the Generalized Likelihood Uncertainty estimation (GLUE) method to evaluate parameter sensitivity. In other words, we sort all the runs to find the best-fitting parameter combinations, which helps us understand the most likely values of these unknown parameters in our hydrological model.
 
 There are three main objectives for this homework:  
1) Set up the Monte Carlo analysis
2) Run the MC simulation for ONE of the years in the study period and perform a GLUE sensitivity analysis  
3) Compare the different objective functions.

A lot of the code in this homework will be provided.

#### Setup
Import packages, including the "progress" and "tictoc" packages. These will allow us to time our loops and functions

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = TRUE, comment = TRUE, message = TRUE, error = TRUE)
# library(tidyverse)
# library(lubridate)
# library(progress)
# library(tictoc)
# library(plotly)
```

Read data - this is the same PQ data we have worked with in previous modules.

```{r, include=FALSE, warning=FALSE}
# rm(list = ls(all = TRUE)) # clear global environment
# 
# indata <- read_csv("P_Q_1996_2011.csv")
# indata <- indata %>%
#   mutate(Date = mdy(Date)) %>% # bring the date colum in shape
#   mutate(wtr_yr = if_else(month(Date) > 9, year(Date) + 1, year(Date))) # create a water year column
# 
# # choose the 2006 water year
# PQ <- indata %>%
#   filter(wtr_yr == 2006)
```

Define variables

```{r, include=FALSE, warning=FALSE}
# tau <- 1:nrow(PQ) # simple timestep counter
# Pobs <- PQ$RainMelt_mm # observed precipitation
# Qobs <- PQ$Discharge_mm # observed streamflow
```

#### Parameter initialization
This chunk has two purposes. The first is to set up the number of iterations for the Monte Carlo simulation. The entire model code is essentially wrapped into the main MC for loop. Each iteration of that loop is one full model realization: loss function, TF, convolution, model fit assessment (objective function). For each model run (each MC iteration), we will save the model parameters and respective objective functions in a dataframe. This will be the main source for the GLUE sensitivity analysis at the end. The model parameters are sampled in the main model chunk, this is just the preallocation of the dataframe.  
You will both run your own MC simulation, to set up the code, but will also receive a .Rdata file with 100,000 runs to give you more behavioral runs for the sensitivity analysis and uncertainty bounds. As a tip, while setting up the code, I would recommend setting the number of MC iterations to something low, for example 10 or maybe even 1. Once you have confirmed that your code works, crank up the number of iterations. Set it to 1000 to see how many behavioral runs you get. After that, load the file with the provided runs. 

```{r, include=FALSE, warning=FALSE}
# nx sets the number of Monte Carlo runs
# nx <- 100 # number of runs
# 
# # set up the parameter matrix for the loss function, transfer function, and objective functions
# param <- tibble(
#   Run = vector(mode = "double", nx), # counter for model run
#   b1 = vector(mode = "double", nx),
#   b2 = vector(mode = "double", nx),
#   b3 = vector(mode = "double", nx),
#   a = vector(mode = "double", nx),
#   b = vector(mode = "double", nx),
#   nse = vector(mode = "double", nx),
#   kge = vector(mode = "double", nx),
#   rmse = vector(mode = "double", nx),
#   mae = vector(mode = "double", nx)
# )
```

#### MC Model run
This is the main model chunk. The tic() and toc() statements measure the execution time for the whole chunk. There is also a progressbar in the chunk that3 will run in the console and inform you about the progress of the MC simulation. The loss function parameters are set in the loss function, the TF parameters in the loss function code. For each loop iteration, we will store the parameter values and the simulated discharge in the "param" dataframe. So, if we ran the MC simulation 100 times, we would end up with 100 parameter combinations and simulated discharges.

```{r, include=FALSE, warning=FALSE}
# tic("MC Simulation")
# 
# # initialize progress bar
# pb <- progress_bar$new(
#   format = " downloading [:bar] :percent eta: :eta",
#   total = nx,
#   clear = FALSE,
#   width = 60
# )

# #### MONTE CARLO SETUP (use ii as index and let it run for as many iterations as we have set nx)
# for (ii in 1:nx) {
#   pb$tick() # needed for progress bar
# 
#   # write run number into the parameter matrix. this is just a simple counter.
#   param$Run[ii] <- ii
# 
# 
#   ######## LOSS FUNCTION #########
#   # feel free to ignore the next two lines of code. There can be parameter combinations in the loss function that lead to an execution error. The "while" statement prevents this.
#   p_eff <- 10000 # artificially large value to make the first while loop TRUE
#   while (sum(p_eff) < 0.2 * sum(Pobs) ||
#     sum(p_eff) > sum(Pobs) || is.na(sum(p_eff))) {
#     
#     
#     # define the loss function parameters
#     # Here, you need to specify how to generate the values for the loss function parameters. Use runif() for the sampling. For each loop iteration, we want to create one value for each parameter (and save it in param)
#     param$b1[ii] <- runif(1, 0, 0.2) # let b1 vary from 0 to 0.2
#     param$b2[ii] <- runif(1, 0, 50) # let b2 vary from 0 to 50
#     param$b3[ii] <- runif(1, 0, 50) # let b3 vary from 0 to 50
# 
# 
#     # preallocate the p_eff vector (length of the timeseries)
#     p_eff <- vector(mode = "double", length(tau))
# 
#     # set a starting value for s (you are pulling the value out of the parameter dataframe)
#     s <- param$b3[ii]
# 
#     # loop with loss function
#     for (i in 1:length(p_eff)) {
#       s <- param$b1[ii] * Pobs[i] + (1 - 1 / param$b2[ii]) * s
#       p_eff[i] <- Pobs[i] * s
#     }
# 
# 
#     
#     ####### TRANSFER FUNCTION #######
#     # The next two lines are not really necessary but are some initial quality control on the TF parameters
#     gTF <- tau
#     while (sum(gTF[1:183], na.rm = TRUE) < sum(gTF[184:length(gTF)], na.rm = TRUE)) {
#       # MC randomization for TF parameters
#       param$a[ii] <- runif(1, 0, 20) # set the alpha parameter to a random value between 0 and 20
#       param$b[ii] <- runif(1, 0, 100) # set the beta parameter to a random value between 0 and 100
# 
#       # set up the TF (again, remember that the TF function parameters are coming from the param df and need to be indexed properly)
#       g <- (tau^(param$a[ii] - 1)) / ((param$b[ii]^param$a[ii] * gamma(param$a[ii]))) * exp(-tau / param$b[ii])
# 
#       # normalization
#       gTF <- g / sum(g)
#     } # while (sum(gTF[1:183], na.rm = TRUE) < sum(gTF[184:length(gTF)], na.rm = TRUE)) {
# 
#     # quick plot of gTF
#     qplot(tau, gTF, geom = "line")
# 
# 
# 
#     ####### CONVOLUTION ########
#     # preallocate qsim vector
#     Qsim <- vector(mode = "double", length(p_eff))
# 
#     # start convolution (this code for the second convolution method was developed by a previous student of this class. It cuts execution time by more than 60%)
#     m <- length(p_eff)
#     for (k in 1:length(p_eff)) {
#       Qsim[k:m] <- Qsim[k:m] + p_eff[k] * gTF[1:(m - k + 1)]
#     }
# 
#     # Save Qsim (or q_all) as vector in the parameter dataframe (by creating a list)
#     param$qsim[ii] <- list(Qsim) # this saves a vector in a single df cell
# 
# 
# 
#     ######## MODEL EFFICIENCY AND OBJECTIVE FUNCTIONS ########
#     # This is an important component! We will also save values from several objective functions in the param df.
#     # Use Qsim and Qobs as the two variables (quicker than referencing a df)
# 
#     ### DOUBLE AND TRIPLE CHECK PARENTHESES ############
# 
#     # NSE
#     param$nse[ii] <- 1 - ((sum((Qobs - Qsim)^2)) / sum((Qobs - mean(Qobs))^2))
# 
#     # KGE
#     kge_r <- cor(Qobs, Qsim) # correlation between Qobs and Qsim (simple Pearson)
#     kge_beta <- mean(Qsim) / mean(Qobs) # ratio of the means
#     kge_gamma <- (sd(Qsim) / mean(Qsim)) / (sd(Qobs) / mean(Qobs)) # ratio of the CVs
#     param$kge[ii] <- 1 - sqrt((kge_r - 1)^2 + (kge_beta - 1)^2 + (kge_gamma - 1)^2) # entire obj fct put together
# 
#     # RMSE
#     param$rmse[ii] <- sqrt(sum((Qobs - Qsim)^2) / length(Qobs)) # root mean square error obj fct
# 
#     # MAE
#     param$mae[ii] <- sum(abs(Qobs - Qsim)) / length(Qobs) # mean absolute error obj fct
#   }
# }
# toc()
# 
# # sort parameter matrix in descending order of objective function (best first, worst last). use nse first.
# param <- arrange(param, desc(nse))
# 
# 
# ## plot the runs from the calibration to make sure it works properly
# # this line does a few things: it takes the Q simulations that are stored in param$qsim as a list and "unlists" them into a single vector (unlist(param$qsim)); then it takes that vector and writes it into a matrix with as many columns as nx; then it takes the matrix and converts it to a dataframe. Yes, this seems somewhat convoluted, and I'm sure there is a better way to do this...  
# PQ_plot <- as.data.frame(matrix(unlist(param$qsim), ncol = nx, byrow = F)) %>% 
#   mutate(Date = PQ$Date) %>% # add the date vector
#   pivot_longer(-Date, names_to = "Simulation", values_to = "Value") # make long form
# 
# # plot the simulated flows
# pq_plot <- ggplot(PQ_plot, aes(x=Date, y=Value, color=Simulation)) +
#   geom_line()
# 
# ggplotly(pq_plot)
```

**Q1 (2 pt) How are the loss function and transfer function parameters being sampled? That is, what is the underlying distribution and why did we choose it? (2-3 sentences)**  
ANSWER: 


**Extra point: What does the while loop do in the transfer function calculation? And why is it in there? (1-2 sentences)**  
ANSWER:  



Save or load data

After setting up the MC simulation, we will actually use a pre-created dataset. Running the MC simulation tens of thousands of times will take multiple hours. For that reason, we have done this for you and saved it as an importable data set.

```{r, include=FALSE, warning=FALSE}
# save.image(file = 'AllData.RData')

# load the MC data
# load("AllData.RData")
```

Best run

Now that we have the dataframe with all parameter combinations and all efficiencies, we can plot the best simulation and compare it to the observed discharge
```{r, include=FALSE, warning=FALSE}
# # take the best run (i.e., first row in param df), unlist the simulated discharge, and store it in a dataframe
# PQ$Qsim <- unlist(param$qsim[1])
# 
# # make long form
# PQ_long <- PQ %>%
#   select(-wtr_yr, -RainMelt_mm) %>% # remove the water year and rainmelt columns
#   pivot_longer(names_to = "key", values_to = "value", -Date)
# 
# # plot observed and best simulated discharge in the same figure against the date
# ggplot(PQ_long, aes(x = Date, y = value, color = key)) +
#   theme_bw(base_size = 15) +
#   geom_line() +
#   labs(y = "Discharge (mm/day)", color = {
#   })
```

### Sensitivity analysis

We will use the GLUE methodology to assess parameter sensitivity. We will use GLUE for two purposes: 
1) Assessing parameter sensitivity â€“ Understanding how different parameter values influence model performance
2) Creating an envelope of model simulations â€“ Identifying a range of possible model outputs that fit the observed data 

To start, we need to format the data so we can create dotty plots and density plots using Nash-Sutcliffe Efficiency (NSE) as our performance metric.

When plotting, each parameter should be displayed in its own panel. You can achieve this using facet_wrap() in ggplot2, and be sure to set the axis scaling to "free" so each parameter is properly visualized

```{r, include=FALSE, warning=FALSE}
# # select columns and make long form data
# param_long <- param %>%
#   select(-Run, -kge, -rmse, -mae, -qsim) %>% # remove unnecessary columns. We only want the five parameters and nse
#   pivot_longer(names_to = "key", values_to = "value", -nse) # make long form
# 
# 
# # set nse cutoff for behavioral model simulations. use 0.7 as threshold
# cutoff <- 0.8
# param_long <- param_long %>%
#   filter(nse > cutoff) # use filter() to only use runs with nse greater than the cutoff
# 
# 
# # dotty plots
# ggplot(param_long, aes(x = value, y = nse)) + # x is parameter value, y is nse value
#   geom_point() + # plot as points
#   facet_wrap(vars(key), scales = "free") + # facets are the individual parameters
#   ylim(cutoff, 1) + # sets obj fct axis limit from the cutoff value to 1
#   theme(
#     strip.text = element_text(face = "bold", size = 8),
#     strip.background = element_rect(
#       fill = "gray95",
#       colour = "gray",
#       size = 0.5
#       )
#   )
# 
# 
# # density plots
# ggplot() +
#   theme_bw(base_size = 15) +
#   geom_density(data = param_long, aes(x = value)) + # geom_density() to plot the density
#   facet_wrap(~key, scales = "free") + # facet_wrap() to get each parameter in its own box
#   theme(
#     strip.text = element_text(face = "bold", size = 8),
#     strip.background = element_rect(
#       fill = "gray95",
#       colour = "gray",
#       size = 0.5
#       )
#   )
# 
# 
# # 2d density plots
# ggplot() +
#   geom_density_2d_filled( # geom_density_2d_filled() for the actual density plot
#     data = param_long,
#     aes(x = value, y = nse),
#     alpha = 1,
#     contour_var = "ndensity"
#   ) +
#   geom_point( # geom_point() to show the indivudal runs
#     data = param_long,
#     aes(x = value, y = nse),
#     shape = 1,
#     alpha = 0.2,
#     size = 0.5,
#     stroke = 0.2,
#     color = "black"
#   ) +
#   theme_bw(base_size = 15) +
#   facet_wrap(~key, scales = "free") +
#   theme(
#     strip.text = element_text(face = "bold", size = 8),
#     strip.background = element_rect(
#       fill = "gray95",
#       colour = "gray",
#       linewidth = 0.5
#     )
#   ) +
#   labs(x = "Value", y = "NSE (-)") +
#   theme(legend.title = element_blank(), legend.position = "none")
```

**Q2 (4 pts) Describe the sensitivity analysis with the three different plots. Are the parameters sensitive? Which ones are, which ones are not? Does this affect your "trust" in the model? (5-8 sentences)**    
ANSWER: 



**Q3 (4 pts) What are the differences between the dotty plots and the density plots? What are the differences between the two density plots? (2-3 sentences)**  ANSWER: 
 

Uncertainty bounds
In this section, we will generate uncertainty bounds for our simulation results. Instead of using all model runs, we will only include the behavioral runsâ€”the ones that meet our performance criteria. This ensures that our uncertainty range reflects only the most realistic simulations.

```{r, include=FALSE, warning=FALSE}
# # remove non-behavioral runs using the cutoff
# param_ci <- param %>%
#   filter(nse > 0.872) # only use obj function (nse) values above the previously defined threshold
# 
# # make df with all of the top runs. this saves each of the top simulated Q time series in its own column.
# # the columns are called V1 through Vn, with V1 being the best simulation and Vn the worst simulation of the behavioral runs.
# Qruns <-
#   as_tibble(matrix(
#     unlist(param_ci$qsim),
#     ncol = nrow(param_ci),
#     byrow = F
#   ), .name_repair = NULL)
# 
# # combine Qruns with date and observed runoff from the PQ data frame. additionally, calculate mins and maxs
# Qruns <-
#   bind_cols(Date = PQ$Date, Qruns) %>% # bind_cols() to combine Date, RainMelt_mm, and Qruns
#   mutate(Qmin = apply(Qruns, 1, min)) %>% # get the rowmin for simulated Qs
#   mutate(Qmax = apply(Qruns, 1, max)) # get the rowmax for simualted Qs
# 
# # long form
# Qruns_long <- Qruns %>%
#   # select(-Discharge_mm, -Qsim) %>% # remove observed and best simulated discharge
#   pivot_longer(names_to = "key", values_to = "value", -Date) # make long form
# 
# # plot with all simulated runs
# ggplot() +
#   geom_line(data = Qruns_long, aes(x = Date, y = value, color = key)) + # plot of all simulated runs. Use Qruns_long here.
#   guides(color=FALSE) +
#   geom_line(
#     data = Qruns,
#     aes(x = Date, y = V1, color = "Best run"),
#     size = 1
#   ) + # plot of best simulation. Use Qruns here. V1 is the best simulated discharge
#   labs(y = "Q (mm/day)", x = {
#   }, color = {
#   })
# 
# # real min and max envelope. You need Qruns for the simulated Q and envelope and PQ to plot the observed streamflow.
# ggplot() +
#   geom_ribbon(data = Qruns, aes(x = Date, ymin = Qmin, ymax = Qmax)) + # plot of envelopes. look up geom function that allows you to plot a shaded area between two lines
#   # plot the best simulated run. remember, that is V1 in the Qruns df
#   geom_line(
#     data = Qruns,
#     aes(x = Date, y = V1, color = "Best run"),
#     size = 0.6
#   ) + # plot of best simulation
#   geom_line(
#     data = PQ,
#     aes(x = Date, y = Discharge_mm, color = "Observed Q"),
#     size = 0.6
#   ) + # plot of observed Q
#   labs(y = "Q (mm/day)", x = {
#   }, color = {
#   })
```

**Q4 (3 pts) Describe what the envelope actually is. Could we say we are dealing with confidence or prediction intervals? (2-3 sentences)**   
Hint: Think about what the envelope is capturing. Does it reflect uncertainty in the model structure and parameters or does it describe the variability in future observations?
ANSWER: 



**Q5 (3 pts) If you inspect the individual model runs (in the Qruns df), you will notice that they all perform somewhat poorly when it comes to the initial baseflow. Why is that and what could you do to change this? (Note: you don't have to actually do this, just describe how you might approach that issue (2-3 sentences)**  
Hint: Consider factors such as parameter initialization, storage effects, or missing processes in the model structure. What tuning or modifications could address this? 
ANSWER: 


**Q6 (4 pts) Run the provided code to generate a plot comparing the best model run for each objective function. Then, analyze the differences in model performance by answering the following:**
Which objective function provides the best match to observed runoff overall?
How do the different functions perform in capturing peak flow events?
Which function best represents baseflow conditions? Which struggles the most?
If you were to prioritize accuracy in low-flow conditions, which objective function might you choose and why?** 
ANSWER: 






The coding steps are: 1) get the simulated q vector with the best run for each objective function, 2) put them in a dataframe/tibble, 3) create the long form, 4) plot the long form dataframe/tibble. These steps are just ONE possible outline how the coding steps can be broken up.
```{r, include=FALSE, warning=FALSE}
# # sort the param dataframe to select the best objective functions and unlist the relevant qsim values from the initial param dataset
# param <- arrange(param, desc(param$nse)) # nse
# q1 <- unlist(param$qsim[1])
# param <- arrange(param, desc(param$kge)) # kge
# q2 <- unlist(param$qsim[1])
# param <- arrange(param, param$rmse) # rmse
# q3 <- unlist(param$qsim[1])
# param <- arrange(param, param$mae) # mae
# q4 <- unlist(param$qsim[1])
# 
# 
# # Create dataframe with date and the best runs for each obj function
# PQobjfuns <- tibble(
#   Date = PQ$Date,
#   Qsim_nse = q1,
#   Qsim_kge = q2,
#   Qsim_rmse = q3,
#   Qsim_mae = q4,
#   Qobs = Qobs
# )
# 
# # Create a long form tibble
# PQobjfuns_long <- PQobjfuns %>%
#   pivot_longer(names_to = "key", values_to = "value", -Date)
# 
# # Plot up the data
# 
# # Plot up the four simulations and label them accordingly in the legend.
# # places the legend inside the plot window in the upper left corner to maximize plot space
# # remember that you can zoom into the plot with plotly
# all_obj_fcts <- ggplot() +
#   geom_line(data = PQobjfuns_long, aes(x = Date, y = value, color = key)) +
#   labs(y = "Discharge (mm/day)") +
#   scale_color_discrete(
#     name = "Obj. Function",
#     labels = c(
#       "Observed Runoff",
#       "Kling-Gupta Efficiency",
#       "Mean Absolute Error",
#       "Nash-Sutliffe Efficiency",
#       "Root Mean Square Error"
#     )
#   ) +
#   theme(legend.position = c(0.2, 0.7)) # places the legend inside the plot window
# 
# ggplotly(all_obj_fcts)
```

Response surface
```{r, include=FALSE, warning=FALSE}
# param_surf <- param %>%
#   select(-Run, -qsim) %>%
#   drop_na() %>%
#   filter(nse >= 0)
# 
# ggplot() +
#   geom_density_2d_filled(data = param_surf, aes(x = a, y = b))
# 
# ggplot() +
#   geom_contour(data = param_surf, aes(x = a, y = b, z = nse))
```

